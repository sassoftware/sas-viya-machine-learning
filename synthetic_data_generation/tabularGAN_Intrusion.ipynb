{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swat as sw\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'd',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'y',\n",
       " 'z',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'label']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load Intusion data\n",
    "df = pd.read_csv('../gan-testing/data/intrusion_short_col.csv')\n",
    "discrete =\"a,b,d,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,y,z,aa,ab,label\"\n",
    "discrete = discrete.split(',')\n",
    "discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>k</th>\n",
       "      <th>...</th>\n",
       "      <th>ah</th>\n",
       "      <th>aj</th>\n",
       "      <th>ak</th>\n",
       "      <th>al</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>ao</th>\n",
       "      <th>ap</th>\n",
       "      <th>aq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>snmpgetattack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>snmpgetattack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b   d    e    f  g  h  i  j  k  ...   ah   aj    ak    al   am   an  \\\n",
       "0  0  udp  SF  105  146  0  0  0  0  0  ...  254  1.0  0.01  0.00  0.0  0.0   \n",
       "1  0  udp  SF  105  146  0  0  0  0  0  ...  254  1.0  0.01  0.00  0.0  0.0   \n",
       "2  0  udp  SF  105  146  0  0  0  0  0  ...  254  1.0  0.01  0.00  0.0  0.0   \n",
       "3  0  udp  SF  105  146  0  0  0  0  0  ...  254  1.0  0.01  0.00  0.0  0.0   \n",
       "4  0  udp  SF  105  146  0  0  0  0  0  ...  254  1.0  0.01  0.01  0.0  0.0   \n",
       "\n",
       "    ao   ap   aq          label  \n",
       "0  0.0  0.0  0.0         normal  \n",
       "1  0.0  0.0  0.0         normal  \n",
       "2  0.0  0.0  0.0         normal  \n",
       "3  0.0  0.0  0.0  snmpgetattack  \n",
       "4  0.0  0.0  0.0  snmpgetattack  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop('c', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_icmp</th>\n",
       "      <th>b_tcp</th>\n",
       "      <th>b_udp</th>\n",
       "      <th>d_OTH</th>\n",
       "      <th>d_REJ</th>\n",
       "      <th>d_RSTO</th>\n",
       "      <th>d_RSTOS0</th>\n",
       "      <th>d_RSTR</th>\n",
       "      <th>d_S0</th>\n",
       "      <th>d_S1</th>\n",
       "      <th>...</th>\n",
       "      <th>label_snmpgetattack</th>\n",
       "      <th>label_snmpguess</th>\n",
       "      <th>label_sqlattack</th>\n",
       "      <th>label_teardrop</th>\n",
       "      <th>label_udpstorm.</th>\n",
       "      <th>label_warezmaster</th>\n",
       "      <th>label_worm.</th>\n",
       "      <th>label_xlock</th>\n",
       "      <th>label_xsnoop</th>\n",
       "      <th>label_xterm.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b_icmp  b_tcp  b_udp  d_OTH  d_REJ  d_RSTO  d_RSTOS0  d_RSTR  d_S0  d_S1  \\\n",
       "0       0      0      1      0      0       0         0       0     0     0   \n",
       "1       0      0      1      0      0       0         0       0     0     0   \n",
       "2       0      0      1      0      0       0         0       0     0     0   \n",
       "3       0      0      1      0      0       0         0       0     0     0   \n",
       "4       0      0      1      0      0       0         0       0     0     0   \n",
       "\n",
       "   ...  label_snmpgetattack  label_snmpguess  label_sqlattack  label_teardrop  \\\n",
       "0  ...                    0                0                0               0   \n",
       "1  ...                    0                0                0               0   \n",
       "2  ...                    0                0                0               0   \n",
       "3  ...                    1                0                0               0   \n",
       "4  ...                    1                0                0               0   \n",
       "\n",
       "   label_udpstorm.  label_warezmaster  label_worm.  label_xlock  label_xsnoop  \\\n",
       "0                0                  0            0            0             0   \n",
       "1                0                  0            0            0             0   \n",
       "2                0                  0            0            0             0   \n",
       "3                0                  0            0            0             0   \n",
       "4                0                  0            0            0             0   \n",
       "\n",
       "   label_xterm.  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using the Ruiwen's Encoder for ML utility and CTGAN transformer for GAN\n",
    "str_cols= [ 'b', 'd', 'label']\n",
    "num_cols = ['a','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','aa','ab','ac','ad','af','ag','ah','aj','ak','al','am','an','ao','ap','aq']\n",
    "dataframe = pd.DataFrame(df.loc[:,str_cols])\n",
    "\n",
    "one_hot_columns = pd.DataFrame()\n",
    "for col_name, item in dataframe.iteritems():\n",
    "    col = pd.get_dummies(item, prefix=col_name)\n",
    "    one_hot_columns =pd.concat([one_hot_columns,col],axis=1)\n",
    "one_hot_columns.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire data is concat of discrete and contiuous cols\n",
    "intrusion_data = pd.concat([one_hot_columns,df.loc[:,num_cols]],axis=1)\n",
    "\n",
    "my_X = intrusion_data.drop(columns=['label_smurf','label_neptune','label_snmpgetattack','label_mailbomb','label_guess_passwd','label_snmpguess','label_satan','label_warezmaster','label_back','label_mscan','label_apache2.','label_processtable','label_saint','label_portsweep','label_ipsweep','label_httptunnel','label_pod','label_nmap','label_buffer_overflow.','label_multihop','label_sendmail','label_named','label_ps','label_rootkit','label_xterm.','label_teardrop','label_land','label_xlock','label_xsnoop','label_ftp_write','label_phf','label_udpstorm.','label_perl','label_sqlattack','label_worm.','label_loadmodule','label_imap'])\n",
    "my_X = my_X.rename(columns={'label_normal':'label'})\n",
    "\n",
    "orig_X, orig_y = my_X.drop(columns=[\"label\"]),my_X.loc[:,\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311029, 90)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CC=['label_smurf','label_neptune','label_snmpgetattack','label_mailbomb','label_guess_passwd','label_snmpguess','label_satan','label_warezmaster','label_back','label_mscan','label_apache2.','label_processtable','label_saint','label_portsweep','label_ipsweep','label_httptunnel','label_pod','label_nmap','label_buffer_overflow.','label_multihop','label_sendmail','label_named','label_ps','label_rootkit','label_xterm.','label_teardrop','label_land','label_xlock','label_xsnoop','label_ftp_write','label_phf','label_udpstorm.','label_perl','label_sqlattack','label_worm.','label_loadmodule','label_imap']\n",
    "intrusion_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "orig_X_train, orig_X_test, orig_y_train, orig_y_test = train_test_split(orig_X, orig_y, test_size=0.3, random_state=123, stratify=orig_y)\n",
    "\n",
    "orig_y_train = orig_y_train.astype('int')\n",
    "orig_y_test = orig_y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ML models on the train set of the original data\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "names = [\"Decision Tree\",\"Linear SVM\", \"Random Forest\", \"Logistic Regression\",\"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=5,random_state=0),\n",
    "    SVC(kernel = 'linear', max_iter=1000, C=0.025, random_state=0, probability=True),\n",
    "    RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    LogisticRegression(max_iter=1000, random_state=0),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML scores for the original data:\n",
      "Decision Tree Acc:  0.9580104813040543 f-1:  0.9022211130521587 AUC: 0.9925344821740406\n",
      "Linear SVM Acc:  0.8397153543602439 f-1:  0.7034304977196115 AUC: 0.08252903555368275\n",
      "Random Forest Acc:  0.9800447973936062 f-1:  0.9486712978277649 AUC: 0.9984635532096658\n",
      "Logistic Regression Acc:  0.9517088383757194 f-1:  0.8857447132207514 AUC: 0.9852977315264289\n",
      "MLP Acc:  0.9599395556698711 f-1:  0.8901622002820874 AUC: 0.9873817889559448\n"
     ]
    }
   ],
   "source": [
    "print('ML scores for the original data:')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(orig_X_train, orig_y_train)\n",
    "    score = clf.score(orig_X_test, orig_y_test)\n",
    "    y_pred = clf.predict(orig_X_test)\n",
    "    Acc = accuracy_score(orig_y_test, y_pred)\n",
    "    fscore = f1_score(orig_y_test, y_pred, average='binary')\n",
    "    AUC = roc_auc_score(orig_y_test, clf.predict_proba(orig_X_test)[:, 1])\n",
    "    print(name,'Acc: ', Acc, 'f-1: ', fscore, 'AUC:', AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "GAN_train, GAN_test = train_test_split(df, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311029, 41)\n",
      "(217720, 41)\n",
      "(93309, 41)\n"
     ]
    }
   ],
   "source": [
    "print (df.shape)\n",
    "print (GAN_train.shape)\n",
    "print (GAN_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sw.CAS('dl2073.clstr.rnd.sas.com',33789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Added action set 'generativeAdversarialNet'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; actionset</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>generativeAdversarialNet</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.387s</span> &#183; <span class=\"cas-user\">user 3.19s</span> &#183; <span class=\"cas-sys\">sys 2.77s</span> &#183; <span class=\"cas-memory\">mem 0.222MB</span></small></p>"
      ],
      "text/plain": [
       "[actionset]\n",
       "\n",
       " 'generativeAdversarialNet'\n",
       "\n",
       "+ Elapsed: 0.387s, user: 3.19s, sys: 2.77s, mem: 0.222mb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loadactionset('generativeAdversarialNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table GAN_TRAIN in caslib CASUSER(alphel).\n",
      "NOTE: The table GAN_TRAIN has been created in caslib CASUSER(alphel) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; caslib</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASUSER(alphel)</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; tableName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>GAN_TRAIN</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; casTable</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASTable('GAN_TRAIN', caslib='CASUSER(alphel)')</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.712s</span> &#183; <span class=\"cas-user\">user 1.66s</span> &#183; <span class=\"cas-sys\">sys 0.353s</span> &#183; <span class=\"cas-memory\">mem 192MB</span></small></p>"
      ],
      "text/plain": [
       "[caslib]\n",
       "\n",
       " 'CASUSER(alphel)'\n",
       "\n",
       "[tableName]\n",
       "\n",
       " 'GAN_TRAIN'\n",
       "\n",
       "[casTable]\n",
       "\n",
       " CASTable('GAN_TRAIN', caslib='CASUSER(alphel)')\n",
       "\n",
       "+ Elapsed: 0.712s, user: 1.66s, sys: 0.353s, mem: 192mb"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.upload(GAN_train, casout=dict(name='GAN_train', replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table CEN in caslib CASUSER(alphel).\n",
      "NOTE: The table CEN has been created in caslib CASUSER(alphel) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>Centroid_i</th>\n",
       "      <th>weight</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aq</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84472</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aq</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aq</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00095</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aq</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aq</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00579</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>267.19</td>\n",
       "      <td>187.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>a</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00087</td>\n",
       "      <td>61.93</td>\n",
       "      <td>49.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>a</td>\n",
       "      <td>6</td>\n",
       "      <td>0.97705</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>a</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>851.04</td>\n",
       "      <td>79.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>6493.93</td>\n",
       "      <td>5112.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    VarName  Centroid_i   weight     Mean      Std\n",
       "0        aq           1  0.84472     0.00     0.00\n",
       "1        aq           2  0.00076     0.07     0.04\n",
       "2        aq           3  0.00095     0.16     0.07\n",
       "3        aq           4  0.00430     0.04     0.03\n",
       "4        aq           5  0.00579     0.02     0.02\n",
       "..      ...         ...      ...      ...      ...\n",
       "170       a           4  0.00005   267.19   187.48\n",
       "171       a           5  0.00087    61.93    49.42\n",
       "172       a           6  0.97705     0.02     0.76\n",
       "173       a           7  0.00121   851.04    79.24\n",
       "174       a           8  0.00242  6493.93  5112.44\n",
       "\n",
       "[175 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cen = pd.read_csv(\"../gan-testing/data/int_centroids.csv\")\n",
    "s.upload(cen, casout=dict(name='cen', replace=True))\n",
    "cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215174    0\n",
       "214746    1\n",
       "151318    0\n",
       "278297    0\n",
       "261219    0\n",
       "         ..\n",
       "192476    0\n",
       "17730     0\n",
       "28030     0\n",
       "277869    0\n",
       "249342    0\n",
       "Name: l, Length: 217720, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAN_train['l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Using device: GPU 0.\n",
      "NOTE: Epoch i=1, ae_loss=  0.0221.\n",
      "NOTE: Epoch i=2, ae_loss=  0.0169.\n",
      "NOTE: Epoch i=3, ae_loss=  0.0122.\n",
      "NOTE: Epoch i=4, ae_loss=  0.0092.\n",
      "NOTE: Epoch i=5, ae_loss=  0.0092.\n",
      "NOTE: Epoch i=6, ae_loss=  0.0080.\n",
      "NOTE: Epoch i=7, ae_loss=  0.0138.\n",
      "NOTE: Epoch i=8, ae_loss=  0.0113.\n",
      "NOTE: Epoch i=9, ae_loss=  0.0100.\n",
      "NOTE: Epoch i=10, ae_loss=  0.0106.\n",
      "NOTE: Epoch i=11, ae_loss=  0.0092.\n",
      "NOTE: Epoch i=12, ae_loss=  0.0096.\n",
      "NOTE: Epoch i=13, ae_loss=  0.0085.\n",
      "NOTE: Epoch i=14, ae_loss=  0.0084.\n",
      "NOTE: Epoch i=15, ae_loss=  0.0094.\n",
      "NOTE: Epoch i=16, ae_loss=  0.0080.\n",
      "NOTE: Epoch i=17, ae_loss=  0.0087.\n",
      "NOTE: Epoch i=18, ae_loss=  0.0081.\n",
      "NOTE: Epoch i=19, ae_loss=  0.0088.\n",
      "NOTE: Epoch i=20, ae_loss=  0.0087.\n",
      "NOTE: Epoch i=21, ae_loss=  0.0088.\n",
      "NOTE: Epoch i=22, ae_loss=  0.0080.\n",
      "NOTE: Epoch i=23, ae_loss=  0.0081.\n",
      "NOTE: Epoch i=24, ae_loss=  0.0084.\n",
      "NOTE: Epoch i=25, ae_loss=  0.0087.\n",
      "NOTE: Epoch i=26, ae_loss=  0.0077.\n",
      "NOTE: Epoch i=27, ae_loss=  0.0082.\n",
      "NOTE: Epoch i=28, ae_loss=  0.0078.\n",
      "NOTE: Epoch i=29, ae_loss=  0.0082.\n",
      "NOTE: Epoch i=30, ae_loss=  0.0075.\n",
      "NOTE: Epoch i=31, ae_loss=  0.0082.\n",
      "NOTE: Epoch i=32, ae_loss=  0.0071.\n",
      "NOTE: Epoch i=33, ae_loss=  0.0076.\n",
      "NOTE: Epoch i=34, ae_loss=  0.0070.\n",
      "NOTE: Epoch i=35, ae_loss=  0.0076.\n",
      "NOTE: Epoch i=36, ae_loss=  0.0076.\n",
      "NOTE: Epoch i=37, ae_loss=  0.0082.\n",
      "NOTE: Epoch i=38, ae_loss=  0.0074.\n",
      "NOTE: Epoch i=39, ae_loss=  0.0063.\n",
      "NOTE: Epoch i=40, ae_loss=  0.0066.\n",
      "NOTE: Epoch i=41, ae_loss=  0.0066.\n",
      "NOTE: Epoch i=42, ae_loss=  0.0079.\n",
      "NOTE: Epoch i=43, ae_loss=  0.0077.\n",
      "NOTE: Epoch i=44, ae_loss=  0.0070.\n",
      "NOTE: Epoch i=45, ae_loss=  0.0065.\n",
      "NOTE: Epoch i=46, ae_loss=  0.0083.\n",
      "NOTE: Epoch i=47, ae_loss=  0.0073.\n",
      "NOTE: Epoch i=48, ae_loss=  0.0079.\n",
      "NOTE: Epoch i=49, ae_loss=  0.0064.\n",
      "NOTE: Epoch i=50, ae_loss=  0.0065.\n",
      "NOTE: Epoch i=51, ae_loss=  0.0069.\n",
      "NOTE: Epoch i=52, ae_loss=  0.0070.\n",
      "NOTE: Epoch i=53, ae_loss=  0.0069.\n",
      "NOTE: Epoch i=54, ae_loss=  0.0064.\n",
      "NOTE: Epoch i=55, ae_loss=  0.0062.\n",
      "NOTE: Epoch i=56, ae_loss=  0.0065.\n",
      "NOTE: Epoch i=57, ae_loss=  0.0060.\n",
      "NOTE: Epoch i=58, ae_loss=  0.0069.\n",
      "NOTE: Epoch i=59, ae_loss=  0.0070.\n",
      "NOTE: Epoch i=60, ae_loss=  0.0071.\n",
      "NOTE: Epoch i=61, ae_loss=  0.0066.\n",
      "NOTE: Epoch i=62, ae_loss=  0.0069.\n",
      "NOTE: Epoch i=63, ae_loss=  0.0065.\n",
      "NOTE: Epoch i=64, ae_loss=  0.0059.\n",
      "NOTE: Epoch i=65, ae_loss=  0.0054.\n",
      "NOTE: Epoch i=66, ae_loss=  0.0068.\n",
      "NOTE: Epoch i=67, ae_loss=  0.0054.\n",
      "NOTE: Epoch i=68, ae_loss=  0.0057.\n",
      "NOTE: Epoch i=69, ae_loss=  0.0063.\n",
      "NOTE: Epoch i=70, ae_loss=  0.0063.\n",
      "NOTE: Epoch i=71, ae_loss=  0.0060.\n",
      "NOTE: Epoch i=72, ae_loss=  0.0058.\n",
      "NOTE: Epoch i=73, ae_loss=  0.0059.\n",
      "NOTE: Epoch i=74, ae_loss=  0.0055.\n",
      "NOTE: Epoch i=75, ae_loss=  0.0053.\n",
      "NOTE: Epoch i=76, ae_loss=  0.0065.\n",
      "NOTE: Epoch i=77, ae_loss=  0.0061.\n",
      "NOTE: Epoch i=78, ae_loss=  0.0056.\n",
      "NOTE: Epoch i=79, ae_loss=  0.0057.\n",
      "NOTE: Epoch i=80, ae_loss=  0.0062.\n",
      "NOTE: Epoch i=81, ae_loss=  0.0063.\n",
      "NOTE: Epoch i=82, ae_loss=  0.0055.\n",
      "NOTE: Epoch i=83, ae_loss=  0.0061.\n",
      "NOTE: Epoch i=84, ae_loss=  0.0057.\n",
      "NOTE: Epoch i=85, ae_loss=  0.0060.\n",
      "NOTE: Epoch i=86, ae_loss=  0.0056.\n",
      "NOTE: Epoch i=87, ae_loss=  0.0056.\n",
      "NOTE: Epoch i=88, ae_loss=  0.0063.\n",
      "NOTE: Epoch i=89, ae_loss=  0.0060.\n",
      "NOTE: Epoch i=90, ae_loss=  0.0056.\n",
      "NOTE: Epoch i=91, ae_loss=  0.0060.\n",
      "NOTE: Epoch i=92, ae_loss=  0.0059.\n",
      "NOTE: Epoch i=93, ae_loss=  0.0054.\n",
      "NOTE: Epoch i=94, ae_loss=  0.0055.\n",
      "NOTE: Epoch i=95, ae_loss=  0.0051.\n",
      "NOTE: Epoch i=96, ae_loss=  0.0050.\n",
      "NOTE: Epoch i=97, ae_loss=  0.0050.\n",
      "NOTE: Epoch i=98, ae_loss=  0.0055.\n",
      "NOTE: Epoch i=99, ae_loss=  0.0054.\n",
      "NOTE: Epoch i=100, ae_loss=  0.0050.\n",
      "NOTE: Epoch i=101, ae_loss=  0.0054.\n",
      "NOTE: Epoch i=102, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=103, ae_loss=  0.0045.\n",
      "NOTE: Epoch i=104, ae_loss=  0.0053.\n",
      "NOTE: Epoch i=105, ae_loss=  0.0047.\n",
      "NOTE: Epoch i=106, ae_loss=  0.0048.\n",
      "NOTE: Epoch i=107, ae_loss=  0.0047.\n",
      "NOTE: Epoch i=108, ae_loss=  0.0045.\n",
      "NOTE: Epoch i=109, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=110, ae_loss=  0.0046.\n",
      "NOTE: Epoch i=111, ae_loss=  0.0043.\n",
      "NOTE: Epoch i=112, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=113, ae_loss=  0.0045.\n",
      "NOTE: Epoch i=114, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=115, ae_loss=  0.0043.\n",
      "NOTE: Epoch i=116, ae_loss=  0.0045.\n",
      "NOTE: Epoch i=117, ae_loss=  0.0046.\n",
      "NOTE: Epoch i=118, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=119, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=120, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=121, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=122, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=123, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=124, ae_loss=  0.0043.\n",
      "NOTE: Epoch i=125, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=126, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=127, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=128, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=129, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=130, ae_loss=  0.0043.\n",
      "NOTE: Epoch i=131, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=132, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=133, ae_loss=  0.0042.\n",
      "NOTE: Epoch i=134, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=135, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=136, ae_loss=  0.0047.\n",
      "NOTE: Epoch i=137, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=138, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=139, ae_loss=  0.0039.\n",
      "NOTE: Epoch i=140, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=141, ae_loss=  0.0042.\n",
      "NOTE: Epoch i=142, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=143, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=144, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=145, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=146, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=147, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=148, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=149, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=150, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=151, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=152, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=153, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=154, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=155, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=156, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=157, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=158, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=159, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=160, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=161, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=162, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=163, ae_loss=  0.0041.\n",
      "NOTE: Epoch i=164, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=165, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=166, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=167, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=168, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=169, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=170, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=171, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=172, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=173, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=174, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=175, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=176, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=177, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=178, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=179, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=180, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=181, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=182, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=183, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=184, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=185, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=186, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=187, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=188, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=189, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=190, ae_loss=  0.0040.\n",
      "NOTE: Epoch i=191, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=192, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=193, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=194, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=195, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=196, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=197, ae_loss=  0.0037.\n",
      "NOTE: Epoch i=198, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=199, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=200, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=201, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=202, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=203, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=204, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=205, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=206, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=207, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=208, ae_loss=  0.0038.\n",
      "NOTE: Epoch i=209, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=210, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=211, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=212, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=213, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=214, ae_loss=  0.0035.\n",
      "NOTE: Epoch i=215, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=216, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=217, ae_loss=  0.0033.\n",
      "NOTE: Epoch i=218, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=219, ae_loss=  0.0034.\n",
      "NOTE: Epoch i=220, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=221, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=222, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=223, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=224, ae_loss=  0.0036.\n",
      "NOTE: Epoch i=225, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=226, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=227, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=228, ae_loss=  0.0031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Epoch i=229, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=230, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=231, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=232, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=233, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=234, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=235, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=236, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=237, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=238, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=239, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=240, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=241, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=242, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=243, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=244, ae_loss=  0.0029.\n",
      "NOTE: Epoch i=245, ae_loss=  0.0032.\n",
      "NOTE: Epoch i=246, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=247, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=248, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=249, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=250, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=251, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=252, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=253, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=254, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=255, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=256, ae_loss=  0.0030.\n",
      "NOTE: Epoch i=257, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=258, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=259, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=260, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=261, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=262, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=263, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=264, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=265, ae_loss=  0.0021.\n",
      "NOTE: Epoch i=266, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=267, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=268, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=269, ae_loss=  0.0020.\n",
      "NOTE: Epoch i=270, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=271, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=272, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=273, ae_loss=  0.0022.\n",
      "NOTE: Epoch i=274, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=275, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=276, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=277, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=278, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=279, ae_loss=  0.0021.\n",
      "NOTE: Epoch i=280, ae_loss=  0.0028.\n",
      "NOTE: Epoch i=281, ae_loss=  0.0020.\n",
      "NOTE: Epoch i=282, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=283, ae_loss=  0.0027.\n",
      "NOTE: Epoch i=284, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=285, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=286, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=287, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=288, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=289, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=290, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=291, ae_loss=  0.0026.\n",
      "NOTE: Epoch i=292, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=293, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=294, ae_loss=  0.0022.\n",
      "NOTE: Epoch i=295, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=296, ae_loss=  0.0031.\n",
      "NOTE: Epoch i=297, ae_loss=  0.0023.\n",
      "NOTE: Epoch i=298, ae_loss=  0.0024.\n",
      "NOTE: Epoch i=299, ae_loss=  0.0025.\n",
      "NOTE: Epoch i=300, ae_loss=  0.0021.\n",
      "NOTE: Epoch i=1, g_loss=  2.7653, d_loss= -2.7818.\n",
      "NOTE: Epoch i=2, g_loss=  2.9764, d_loss= -3.0672.\n",
      "NOTE: Epoch i=3, g_loss=  2.4459, d_loss= -2.7511.\n",
      "NOTE: Epoch i=4, g_loss=  1.9858, d_loss= -1.8576.\n",
      "NOTE: Epoch i=5, g_loss=  1.1801, d_loss= -1.4669.\n",
      "NOTE: Epoch i=6, g_loss=  0.9189, d_loss= -1.3494.\n",
      "NOTE: Epoch i=7, g_loss=  1.4488, d_loss= -1.0311.\n",
      "NOTE: Epoch i=8, g_loss=  2.0487, d_loss= -1.5191.\n",
      "NOTE: Epoch i=9, g_loss=  1.2795, d_loss= -1.3461.\n",
      "NOTE: Epoch i=10, g_loss= -0.3429, d_loss=  0.2073.\n",
      "NOTE: Epoch i=11, g_loss= -0.7046, d_loss=  0.5154.\n",
      "NOTE: Epoch i=12, g_loss= -0.9467, d_loss= -0.2986.\n",
      "NOTE: Epoch i=13, g_loss= -0.1340, d_loss= -0.1927.\n",
      "NOTE: Epoch i=14, g_loss= -0.3235, d_loss= -0.1339.\n",
      "NOTE: Epoch i=15, g_loss= -1.4570, d_loss=  0.2714.\n",
      "NOTE: Epoch i=16, g_loss= -1.4977, d_loss= -0.1479.\n",
      "NOTE: Epoch i=17, g_loss= -1.3726, d_loss=  0.6693.\n",
      "NOTE: Epoch i=18, g_loss= -2.1123, d_loss=  0.3740.\n",
      "NOTE: Epoch i=19, g_loss= -1.7566, d_loss= -0.1989.\n",
      "NOTE: Epoch i=20, g_loss= -1.9133, d_loss=  0.2495.\n",
      "NOTE: Epoch i=21, g_loss= -2.2684, d_loss=  0.3579.\n",
      "NOTE: Epoch i=22, g_loss= -2.6647, d_loss=  0.0546.\n",
      "NOTE: Epoch i=23, g_loss= -2.9388, d_loss= -0.1418.\n",
      "NOTE: Epoch i=24, g_loss= -2.2214, d_loss= -0.2651.\n",
      "NOTE: Epoch i=25, g_loss= -2.1554, d_loss= -0.1740.\n",
      "NOTE: Epoch i=26, g_loss= -1.5462, d_loss= -0.0323.\n",
      "NOTE: Epoch i=27, g_loss= -1.5614, d_loss= -0.1195.\n",
      "NOTE: Epoch i=28, g_loss= -1.6294, d_loss= -0.0627.\n",
      "NOTE: Epoch i=29, g_loss= -0.7180, d_loss= -0.4378.\n",
      "NOTE: Epoch i=30, g_loss= -0.1838, d_loss= -0.2975.\n",
      "NOTE: Epoch i=31, g_loss= -0.2214, d_loss= -0.3802.\n",
      "NOTE: Epoch i=32, g_loss= -0.3461, d_loss= -0.1920.\n",
      "NOTE: Epoch i=33, g_loss= -0.0385, d_loss= -0.4434.\n",
      "NOTE: Epoch i=34, g_loss= -0.3227, d_loss= -0.3420.\n",
      "NOTE: Epoch i=35, g_loss=  0.0029, d_loss= -0.2269.\n",
      "NOTE: Epoch i=36, g_loss= -0.1547, d_loss= -0.4455.\n",
      "NOTE: Epoch i=37, g_loss= -0.1867, d_loss=  0.1403.\n",
      "NOTE: Epoch i=38, g_loss=  0.0496, d_loss=  0.0331.\n",
      "NOTE: Epoch i=39, g_loss=  0.0173, d_loss=  0.3281.\n",
      "NOTE: Epoch i=40, g_loss=  0.0903, d_loss= -0.0271.\n",
      "NOTE: Epoch i=41, g_loss=  0.4073, d_loss= -0.0824.\n",
      "NOTE: Epoch i=42, g_loss= -0.1324, d_loss=  0.0356.\n",
      "NOTE: Epoch i=43, g_loss=  0.6311, d_loss=  0.0145.\n",
      "NOTE: Epoch i=44, g_loss=  1.1475, d_loss= -0.1085.\n",
      "NOTE: Epoch i=45, g_loss=  0.4276, d_loss= -0.1126.\n",
      "NOTE: Epoch i=46, g_loss=  0.1594, d_loss=  0.0483.\n",
      "NOTE: Epoch i=47, g_loss=  0.3227, d_loss=  0.4475.\n",
      "NOTE: Epoch i=48, g_loss=  0.0881, d_loss= -0.3315.\n",
      "NOTE: Epoch i=49, g_loss=  0.3903, d_loss=  0.0638.\n",
      "NOTE: Epoch i=50, g_loss=  0.6968, d_loss= -0.0681.\n",
      "NOTE: Epoch i=51, g_loss=  0.3536, d_loss= -0.3304.\n",
      "NOTE: Epoch i=52, g_loss=  0.4485, d_loss= -0.2569.\n",
      "NOTE: Epoch i=53, g_loss=  0.6226, d_loss= -0.5615.\n",
      "NOTE: Epoch i=54, g_loss=  0.6934, d_loss=  0.5790.\n",
      "NOTE: Epoch i=55, g_loss=  1.0710, d_loss=  0.5086.\n",
      "NOTE: Epoch i=56, g_loss=  0.7547, d_loss= -0.4223.\n",
      "NOTE: Epoch i=57, g_loss=  0.5563, d_loss= -0.3027.\n",
      "NOTE: Epoch i=58, g_loss=  0.9501, d_loss=  0.2180.\n",
      "NOTE: Epoch i=59, g_loss=  1.1955, d_loss= -0.0401.\n",
      "NOTE: Epoch i=60, g_loss=  1.4312, d_loss= -0.4821.\n",
      "NOTE: Epoch i=61, g_loss=  1.2068, d_loss=  0.1680.\n",
      "NOTE: Epoch i=62, g_loss=  0.8186, d_loss=  0.1677.\n",
      "NOTE: Epoch i=63, g_loss=  0.5415, d_loss=  0.6919.\n",
      "NOTE: Epoch i=64, g_loss=  1.2428, d_loss= -0.1943.\n",
      "NOTE: Epoch i=65, g_loss=  0.7827, d_loss= -0.0784.\n",
      "NOTE: Epoch i=66, g_loss=  0.6914, d_loss= -0.2034.\n",
      "NOTE: Epoch i=67, g_loss=  1.0770, d_loss= -0.2876.\n",
      "NOTE: Epoch i=68, g_loss=  1.5215, d_loss= -0.2804.\n",
      "NOTE: Epoch i=69, g_loss=  1.2762, d_loss= -0.3573.\n",
      "NOTE: Epoch i=70, g_loss=  1.4573, d_loss=  0.1866.\n",
      "NOTE: Epoch i=71, g_loss=  1.2978, d_loss= -0.4626.\n",
      "NOTE: Epoch i=72, g_loss=  0.7747, d_loss= -0.1848.\n",
      "NOTE: Epoch i=73, g_loss=  1.6183, d_loss= -0.1058.\n",
      "NOTE: Epoch i=74, g_loss=  1.4579, d_loss=  0.1193.\n",
      "NOTE: Epoch i=75, g_loss=  1.1178, d_loss= -0.4069.\n",
      "NOTE: Epoch i=76, g_loss=  1.2849, d_loss= -0.0419.\n",
      "NOTE: Epoch i=77, g_loss=  1.1435, d_loss=  0.3468.\n",
      "NOTE: Epoch i=78, g_loss=  1.4065, d_loss= -0.1028.\n",
      "NOTE: Epoch i=79, g_loss=  1.5527, d_loss= -0.0291.\n",
      "NOTE: Epoch i=80, g_loss=  1.2565, d_loss=  0.0333.\n",
      "NOTE: Epoch i=81, g_loss=  1.1110, d_loss= -0.7517.\n",
      "NOTE: Epoch i=82, g_loss=  1.9261, d_loss=  0.2191.\n",
      "NOTE: Epoch i=83, g_loss=  1.4720, d_loss= -0.5538.\n",
      "NOTE: Epoch i=84, g_loss=  0.7956, d_loss= -0.1965.\n",
      "NOTE: Epoch i=85, g_loss=  1.4724, d_loss=  0.3558.\n",
      "NOTE: Epoch i=86, g_loss=  1.5857, d_loss=  0.5131.\n",
      "NOTE: Epoch i=87, g_loss=  1.2560, d_loss=  0.1833.\n",
      "NOTE: Epoch i=88, g_loss=  1.2050, d_loss= -0.3115.\n",
      "NOTE: Epoch i=89, g_loss=  1.5723, d_loss= -0.2631.\n",
      "NOTE: Epoch i=90, g_loss=  1.9196, d_loss= -0.3577.\n",
      "NOTE: Epoch i=91, g_loss=  1.4850, d_loss= -0.7219.\n",
      "NOTE: Epoch i=92, g_loss=  1.2665, d_loss=  0.5448.\n",
      "NOTE: Epoch i=93, g_loss=  2.0234, d_loss= -0.6136.\n",
      "NOTE: Epoch i=94, g_loss=  1.9561, d_loss=  0.4931.\n",
      "NOTE: Epoch i=95, g_loss=  1.5290, d_loss= -0.4636.\n",
      "NOTE: Epoch i=96, g_loss=  1.4085, d_loss=  0.5723.\n",
      "NOTE: Epoch i=97, g_loss=  2.1156, d_loss= -0.2395.\n",
      "NOTE: Epoch i=98, g_loss=  1.5757, d_loss=  0.9028.\n",
      "NOTE: Epoch i=99, g_loss=  2.0295, d_loss=  0.2533.\n",
      "NOTE: Epoch i=100, g_loss=  1.2698, d_loss=  0.7423.\n",
      "NOTE: Epoch i=101, g_loss=  1.3749, d_loss=  0.3337.\n",
      "NOTE: Epoch i=102, g_loss=  1.8211, d_loss= -0.0974.\n",
      "NOTE: Epoch i=103, g_loss=  1.1174, d_loss=  0.1929.\n",
      "NOTE: Epoch i=104, g_loss=  1.3971, d_loss=  0.1373.\n",
      "NOTE: Epoch i=105, g_loss=  1.7949, d_loss=  0.1550.\n",
      "NOTE: Epoch i=106, g_loss=  1.8445, d_loss= -0.1027.\n",
      "NOTE: Epoch i=107, g_loss=  1.6501, d_loss=  0.5319.\n",
      "NOTE: Epoch i=108, g_loss=  1.1070, d_loss=  0.7523.\n",
      "NOTE: Epoch i=109, g_loss=  1.7703, d_loss=  0.2995.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Epoch i=110, g_loss=  2.0296, d_loss= -0.0146.\n",
      "NOTE: Epoch i=111, g_loss=  0.5425, d_loss=  0.3522.\n",
      "NOTE: Epoch i=112, g_loss=  1.7419, d_loss=  0.2535.\n",
      "NOTE: Epoch i=113, g_loss=  1.9174, d_loss=  0.1255.\n",
      "NOTE: Epoch i=114, g_loss=  2.0853, d_loss=  0.7367.\n",
      "NOTE: Epoch i=115, g_loss=  1.3197, d_loss=  0.2240.\n",
      "NOTE: Epoch i=116, g_loss=  1.7888, d_loss=  0.5310.\n",
      "NOTE: Epoch i=117, g_loss=  0.5434, d_loss= -0.5547.\n",
      "NOTE: Epoch i=118, g_loss=  1.3687, d_loss= -0.6897.\n",
      "NOTE: Epoch i=119, g_loss=  1.1328, d_loss= -0.4032.\n",
      "NOTE: Epoch i=120, g_loss=  0.7011, d_loss=  0.1934.\n",
      "NOTE: Epoch i=121, g_loss=  1.1064, d_loss=  0.1052.\n",
      "NOTE: Epoch i=122, g_loss=  0.8064, d_loss= -0.2364.\n",
      "NOTE: Epoch i=123, g_loss=  1.0327, d_loss= -0.1170.\n",
      "NOTE: Epoch i=124, g_loss=  0.6796, d_loss=  0.0723.\n",
      "NOTE: Epoch i=125, g_loss=  1.5226, d_loss=  0.0314.\n",
      "NOTE: Epoch i=126, g_loss=  1.4207, d_loss= -0.2888.\n",
      "NOTE: Epoch i=127, g_loss=  0.7540, d_loss=  0.2305.\n",
      "NOTE: Epoch i=128, g_loss=  0.9361, d_loss= -0.4202.\n",
      "NOTE: Epoch i=129, g_loss=  1.0835, d_loss=  0.4585.\n",
      "NOTE: Epoch i=130, g_loss=  1.2708, d_loss= -0.4987.\n",
      "NOTE: Epoch i=131, g_loss=  0.8676, d_loss=  0.1689.\n",
      "NOTE: Epoch i=132, g_loss=  1.1961, d_loss= -0.1193.\n",
      "NOTE: Epoch i=133, g_loss=  0.5576, d_loss=  0.6919.\n",
      "NOTE: Epoch i=134, g_loss=  1.3878, d_loss= -0.0914.\n",
      "NOTE: Epoch i=135, g_loss=  1.1460, d_loss=  0.1421.\n",
      "NOTE: Epoch i=136, g_loss=  1.4574, d_loss= -0.6560.\n",
      "NOTE: Epoch i=137, g_loss=  1.4691, d_loss= -0.7897.\n",
      "NOTE: Epoch i=138, g_loss=  0.9397, d_loss=  0.1540.\n",
      "NOTE: Epoch i=139, g_loss=  0.8314, d_loss=  0.4824.\n",
      "NOTE: Epoch i=140, g_loss=  1.2088, d_loss= -0.2498.\n",
      "NOTE: Epoch i=141, g_loss=  1.2347, d_loss= -0.0050.\n",
      "NOTE: Epoch i=142, g_loss=  1.7070, d_loss=  0.0095.\n",
      "NOTE: Epoch i=143, g_loss=  0.6388, d_loss=  0.7263.\n",
      "NOTE: Epoch i=144, g_loss=  1.1619, d_loss= -0.1001.\n",
      "NOTE: Epoch i=145, g_loss=  1.0403, d_loss=  0.3503.\n",
      "NOTE: Epoch i=146, g_loss=  0.9719, d_loss= -0.7243.\n",
      "NOTE: Epoch i=147, g_loss=  1.2266, d_loss=  0.2850.\n",
      "NOTE: Epoch i=148, g_loss=  1.0130, d_loss= -0.4522.\n",
      "NOTE: Epoch i=149, g_loss=  0.4096, d_loss=  0.4081.\n",
      "NOTE: Epoch i=150, g_loss=  0.7820, d_loss= -0.5250.\n",
      "NOTE: Epoch i=151, g_loss=  0.9115, d_loss=  0.5793.\n",
      "NOTE: Epoch i=152, g_loss=  1.3278, d_loss= -0.9122.\n",
      "NOTE: Epoch i=153, g_loss=  1.4353, d_loss= -0.4274.\n",
      "NOTE: Epoch i=154, g_loss=  2.1283, d_loss=  0.2494.\n",
      "NOTE: Epoch i=155, g_loss=  1.5759, d_loss= -0.0477.\n",
      "NOTE: Epoch i=156, g_loss=  1.3612, d_loss= -0.1145.\n",
      "NOTE: Epoch i=157, g_loss=  1.4006, d_loss= -0.2164.\n",
      "NOTE: Epoch i=158, g_loss=  0.4206, d_loss= -0.5394.\n",
      "NOTE: Epoch i=159, g_loss=  1.7214, d_loss= -0.2656.\n",
      "NOTE: Epoch i=160, g_loss=  0.9273, d_loss= -0.2704.\n",
      "NOTE: Epoch i=161, g_loss=  1.2692, d_loss= -0.8224.\n",
      "NOTE: Epoch i=162, g_loss=  0.2325, d_loss=  0.4045.\n",
      "NOTE: Epoch i=163, g_loss=  1.0100, d_loss= -0.2566.\n",
      "NOTE: Epoch i=164, g_loss=  0.4050, d_loss=  0.5644.\n",
      "NOTE: Epoch i=165, g_loss=  0.9755, d_loss= -0.1231.\n",
      "NOTE: Epoch i=166, g_loss=  0.7791, d_loss= -0.2915.\n",
      "NOTE: Epoch i=167, g_loss=  0.6878, d_loss= -0.2120.\n",
      "NOTE: Epoch i=168, g_loss=  0.6033, d_loss=  0.3144.\n",
      "NOTE: Epoch i=169, g_loss=  0.6081, d_loss= -0.3136.\n",
      "NOTE: Epoch i=170, g_loss=  0.6317, d_loss= -0.6169.\n",
      "NOTE: Epoch i=171, g_loss=  1.1244, d_loss=  0.3484.\n",
      "NOTE: Epoch i=172, g_loss=  0.4962, d_loss=  1.1454.\n",
      "NOTE: Epoch i=173, g_loss=  1.2385, d_loss=  0.7418.\n",
      "NOTE: Epoch i=174, g_loss=  1.8296, d_loss=  0.2340.\n",
      "NOTE: Epoch i=175, g_loss=  1.1884, d_loss= -0.6191.\n",
      "NOTE: Epoch i=176, g_loss=  1.5342, d_loss= -0.2565.\n",
      "NOTE: Epoch i=177, g_loss=  1.6138, d_loss= -0.5884.\n",
      "NOTE: Epoch i=178, g_loss=  1.0140, d_loss= -0.7244.\n",
      "NOTE: Epoch i=179, g_loss=  1.8500, d_loss=  0.3374.\n",
      "NOTE: Epoch i=180, g_loss=  1.5637, d_loss= -0.6782.\n",
      "NOTE: Epoch i=181, g_loss=  0.9869, d_loss= -0.7152.\n",
      "NOTE: Epoch i=182, g_loss=  1.6233, d_loss= -0.2102.\n",
      "NOTE: Epoch i=183, g_loss=  0.7747, d_loss= -0.6572.\n",
      "NOTE: Epoch i=184, g_loss=  1.2731, d_loss= -0.8913.\n",
      "NOTE: Epoch i=185, g_loss=  0.4295, d_loss=  0.4018.\n",
      "NOTE: Epoch i=186, g_loss=  0.5120, d_loss= -0.4217.\n",
      "NOTE: Epoch i=187, g_loss=  1.1971, d_loss=  0.3950.\n",
      "NOTE: Epoch i=188, g_loss=  0.2284, d_loss= -0.8632.\n",
      "NOTE: Epoch i=189, g_loss=  0.7209, d_loss= -0.0563.\n",
      "NOTE: Epoch i=190, g_loss=  0.9904, d_loss=  0.2995.\n",
      "NOTE: Epoch i=191, g_loss=  0.9794, d_loss=  0.1628.\n",
      "NOTE: Epoch i=192, g_loss=  1.1889, d_loss=  0.6492.\n",
      "NOTE: Epoch i=193, g_loss=  1.1127, d_loss=  0.8698.\n",
      "NOTE: Epoch i=194, g_loss=  1.5130, d_loss= -0.9136.\n",
      "NOTE: Epoch i=195, g_loss=  1.6976, d_loss= -0.2824.\n",
      "NOTE: Epoch i=196, g_loss=  0.5211, d_loss=  0.1811.\n",
      "NOTE: Epoch i=197, g_loss=  1.1399, d_loss=  0.0795.\n",
      "NOTE: Epoch i=198, g_loss=  0.8533, d_loss=  0.8049.\n",
      "NOTE: Epoch i=199, g_loss=  0.8499, d_loss= -0.4127.\n",
      "NOTE: Epoch i=200, g_loss=  1.1107, d_loss= -0.3784.\n",
      "NOTE: Epoch i=201, g_loss=  1.6472, d_loss= -0.8725.\n",
      "NOTE: Epoch i=202, g_loss=  1.4542, d_loss=  0.4016.\n",
      "NOTE: Epoch i=203, g_loss=  2.3472, d_loss=  0.1512.\n",
      "NOTE: Epoch i=204, g_loss=  0.8125, d_loss=  0.2572.\n",
      "NOTE: Epoch i=205, g_loss=  1.0345, d_loss= -1.5299.\n",
      "NOTE: Epoch i=206, g_loss=  1.2133, d_loss= -0.3675.\n",
      "NOTE: Epoch i=207, g_loss=  1.1618, d_loss= -0.4117.\n",
      "NOTE: Epoch i=208, g_loss=  1.1244, d_loss=  0.3393.\n",
      "NOTE: Epoch i=209, g_loss=  0.7224, d_loss=  0.7469.\n",
      "NOTE: Epoch i=210, g_loss=  0.8596, d_loss= -0.4996.\n",
      "NOTE: Epoch i=211, g_loss=  1.0216, d_loss=  0.7110.\n",
      "NOTE: Epoch i=212, g_loss= -0.0456, d_loss=  0.2476.\n",
      "NOTE: Epoch i=213, g_loss=  0.4042, d_loss= -0.0512.\n",
      "NOTE: Epoch i=214, g_loss=  0.7097, d_loss= -0.1256.\n",
      "NOTE: Epoch i=215, g_loss=  0.8715, d_loss= -0.5043.\n",
      "NOTE: Epoch i=216, g_loss=  1.3743, d_loss=  0.1541.\n",
      "NOTE: Epoch i=217, g_loss=  1.0110, d_loss= -0.5157.\n",
      "NOTE: Epoch i=218, g_loss=  1.2021, d_loss= -0.1917.\n",
      "NOTE: Epoch i=219, g_loss=  0.9500, d_loss=  0.3465.\n",
      "NOTE: Epoch i=220, g_loss=  0.3418, d_loss=  0.1807.\n",
      "NOTE: Epoch i=221, g_loss=  0.8156, d_loss= -0.2382.\n",
      "NOTE: Epoch i=222, g_loss=  0.8678, d_loss= -0.6205.\n",
      "NOTE: Epoch i=223, g_loss=  1.5748, d_loss= -0.1758.\n",
      "NOTE: Epoch i=224, g_loss=  1.5869, d_loss= -0.1437.\n",
      "NOTE: Epoch i=225, g_loss=  0.0375, d_loss=  0.2322.\n",
      "NOTE: Epoch i=226, g_loss=  1.5100, d_loss=  0.8429.\n",
      "NOTE: Epoch i=227, g_loss=  1.0973, d_loss=  0.2481.\n",
      "NOTE: Epoch i=228, g_loss=  0.1568, d_loss=  0.7543.\n",
      "NOTE: Epoch i=229, g_loss=  1.3974, d_loss= -0.4540.\n",
      "NOTE: Epoch i=230, g_loss=  1.3671, d_loss=  0.2801.\n",
      "NOTE: Epoch i=231, g_loss=  1.9257, d_loss= -0.0496.\n",
      "NOTE: Epoch i=232, g_loss=  1.6968, d_loss= -0.4406.\n",
      "NOTE: Epoch i=233, g_loss=  1.4277, d_loss=  0.7907.\n",
      "NOTE: Epoch i=234, g_loss=  1.6268, d_loss= -0.4787.\n",
      "NOTE: Epoch i=235, g_loss=  0.7878, d_loss= -0.3373.\n",
      "NOTE: Epoch i=236, g_loss=  1.1741, d_loss=  0.0865.\n",
      "NOTE: Epoch i=237, g_loss=  0.6886, d_loss=  0.5634.\n",
      "NOTE: Epoch i=238, g_loss=  1.1744, d_loss=  1.1593.\n",
      "NOTE: Epoch i=239, g_loss=  1.1461, d_loss=  0.0836.\n",
      "NOTE: Epoch i=240, g_loss=  1.7026, d_loss= -0.1083.\n",
      "NOTE: Epoch i=241, g_loss=  1.5607, d_loss=  0.2596.\n",
      "NOTE: Epoch i=242, g_loss=  1.1526, d_loss= -0.6166.\n",
      "NOTE: Epoch i=243, g_loss=  0.8328, d_loss=  0.0284.\n",
      "NOTE: Epoch i=244, g_loss=  0.5445, d_loss= -0.0340.\n",
      "NOTE: Epoch i=245, g_loss=  0.4634, d_loss= -0.2782.\n",
      "NOTE: Epoch i=246, g_loss=  0.8250, d_loss= -0.6028.\n",
      "NOTE: Epoch i=247, g_loss=  0.1758, d_loss= -0.6187.\n",
      "NOTE: Epoch i=248, g_loss=  1.5020, d_loss= -0.0448.\n",
      "NOTE: Epoch i=249, g_loss=  0.3374, d_loss= -0.1113.\n",
      "NOTE: Epoch i=250, g_loss=  0.7363, d_loss=  0.7756.\n",
      "NOTE: Epoch i=251, g_loss=  1.2165, d_loss= -0.1917.\n",
      "NOTE: Epoch i=252, g_loss=  1.5787, d_loss= -0.1687.\n",
      "NOTE: Epoch i=253, g_loss=  1.7614, d_loss= -0.2264.\n",
      "NOTE: Epoch i=254, g_loss=  1.7313, d_loss=  0.5891.\n",
      "NOTE: Epoch i=255, g_loss=  1.3980, d_loss=  0.1769.\n",
      "NOTE: Epoch i=256, g_loss=  1.1893, d_loss=  0.3113.\n",
      "NOTE: Epoch i=257, g_loss=  1.7064, d_loss= -0.8570.\n",
      "NOTE: Epoch i=258, g_loss=  1.3052, d_loss=  0.1803.\n",
      "NOTE: Epoch i=259, g_loss=  1.8631, d_loss= -0.3289.\n",
      "NOTE: Epoch i=260, g_loss=  1.9747, d_loss=  0.2772.\n",
      "NOTE: Epoch i=261, g_loss=  0.8428, d_loss=  0.1381.\n",
      "NOTE: Epoch i=262, g_loss=  1.1198, d_loss= -1.0169.\n",
      "NOTE: Epoch i=263, g_loss=  0.2851, d_loss=  0.2833.\n",
      "NOTE: Epoch i=264, g_loss=  1.4143, d_loss= -0.0423.\n",
      "NOTE: Epoch i=265, g_loss=  0.7938, d_loss=  0.4316.\n",
      "NOTE: Epoch i=266, g_loss=  0.7924, d_loss=  0.2692.\n",
      "NOTE: Epoch i=267, g_loss=  1.1609, d_loss= -0.4937.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Epoch i=268, g_loss=  0.6266, d_loss= -0.6269.\n",
      "NOTE: Epoch i=269, g_loss=  0.6160, d_loss= -0.2732.\n",
      "NOTE: Epoch i=270, g_loss=  0.7158, d_loss=  0.0731.\n",
      "NOTE: Epoch i=271, g_loss=  0.9728, d_loss= -0.4628.\n",
      "NOTE: Epoch i=272, g_loss=  0.5439, d_loss= -0.9512.\n",
      "NOTE: Epoch i=273, g_loss=  0.5954, d_loss=  0.6450.\n",
      "NOTE: Epoch i=274, g_loss=  0.8407, d_loss= -0.7943.\n",
      "NOTE: Epoch i=275, g_loss=  1.0484, d_loss=  0.0697.\n",
      "NOTE: Epoch i=276, g_loss=  1.0157, d_loss=  0.0604.\n",
      "NOTE: Epoch i=277, g_loss=  1.3538, d_loss= -0.0613.\n",
      "NOTE: Epoch i=278, g_loss=  0.4221, d_loss=  0.3726.\n",
      "NOTE: Epoch i=279, g_loss= -0.2103, d_loss= -0.3419.\n",
      "NOTE: Epoch i=280, g_loss=  0.9265, d_loss=  0.3179.\n",
      "NOTE: Epoch i=281, g_loss=  0.5910, d_loss= -0.0832.\n",
      "NOTE: Epoch i=282, g_loss=  0.3090, d_loss= -0.4485.\n",
      "NOTE: Epoch i=283, g_loss=  1.0993, d_loss=  0.1883.\n",
      "NOTE: Epoch i=284, g_loss=  1.0252, d_loss=  0.2750.\n",
      "NOTE: Epoch i=285, g_loss=  0.7155, d_loss= -0.8787.\n",
      "NOTE: Epoch i=286, g_loss=  0.8617, d_loss= -0.0870.\n",
      "NOTE: Epoch i=287, g_loss=  0.6478, d_loss= -0.4868.\n",
      "NOTE: Epoch i=288, g_loss=  0.5993, d_loss= -0.2617.\n",
      "NOTE: Epoch i=289, g_loss=  0.9590, d_loss= -0.5033.\n",
      "NOTE: Epoch i=290, g_loss=  0.8390, d_loss=  0.0059.\n",
      "NOTE: Epoch i=291, g_loss=  0.5000, d_loss=  0.2374.\n",
      "NOTE: Epoch i=292, g_loss=  0.6343, d_loss=  0.1883.\n",
      "NOTE: Epoch i=293, g_loss=  1.4496, d_loss=  0.3943.\n",
      "NOTE: Epoch i=294, g_loss=  1.0811, d_loss=  0.0838.\n",
      "NOTE: Epoch i=295, g_loss=  1.8006, d_loss= -0.6450.\n",
      "NOTE: Epoch i=296, g_loss=  0.3108, d_loss=  0.2911.\n",
      "NOTE: Epoch i=297, g_loss=  0.3581, d_loss=  0.1868.\n",
      "NOTE: Epoch i=298, g_loss=  1.0954, d_loss= -0.1227.\n",
      "NOTE: Epoch i=299, g_loss=  1.3463, d_loss=  0.2620.\n",
      "NOTE: Epoch i=300, g_loss=  0.7637, d_loss=  0.5980.\n",
      "NOTE: 14121257 bytes were written to the table \"cpctStore\" in the caslib \"CASUSER(alphel)\".\n",
      "NOTE: tabularGanTrain action completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; IterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch Number\">EpochNumber</th>\n",
       "      <th title=\"Autoencoder Loss\">AutoencoderLoss</th>\n",
       "      <th title=\"Generator Loss\">GeneratorLoss</th>\n",
       "      <th title=\"Discriminator Loss\">DiscriminatorLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310785</td>\n",
       "      <td>0.291099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358057</td>\n",
       "      <td>0.186845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.095447</td>\n",
       "      <td>-0.122725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.346277</td>\n",
       "      <td>0.262042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763684</td>\n",
       "      <td>0.598043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; LevelFreq</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Variable Name\">VarName</th>\n",
       "      <th title=\"Level\">Level</th>\n",
       "      <th title=\"Frequency\">Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>icmp</td>\n",
       "      <td>115421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>tcp</td>\n",
       "      <td>83594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>udp</td>\n",
       "      <td>18705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>OTH</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>REJ</td>\n",
       "      <td>29435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d</td>\n",
       "      <td>S0</td>\n",
       "      <td>12528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d</td>\n",
       "      <td>S1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d</td>\n",
       "      <td>S2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d</td>\n",
       "      <td>S3</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d</td>\n",
       "      <td>SF</td>\n",
       "      <td>173886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>d</td>\n",
       "      <td>SH</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>label</td>\n",
       "      <td>apache2.</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>label</td>\n",
       "      <td>back</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>label</td>\n",
       "      <td>buffer_overflow.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>label</td>\n",
       "      <td>ftp_write</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>label</td>\n",
       "      <td>guess_passwd</td>\n",
       "      <td>3063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>label</td>\n",
       "      <td>httptunnel</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>label</td>\n",
       "      <td>imap</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>label</td>\n",
       "      <td>ipsweep</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>label</td>\n",
       "      <td>land</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>label</td>\n",
       "      <td>loadmodule</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>label</td>\n",
       "      <td>mailbomb</td>\n",
       "      <td>3469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>label</td>\n",
       "      <td>mscan</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>label</td>\n",
       "      <td>multihop</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>label</td>\n",
       "      <td>named</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>label</td>\n",
       "      <td>neptune</td>\n",
       "      <td>40561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>label</td>\n",
       "      <td>nmap</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>label</td>\n",
       "      <td>normal</td>\n",
       "      <td>42537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>label</td>\n",
       "      <td>perl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>label</td>\n",
       "      <td>phf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>label</td>\n",
       "      <td>pod</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>label</td>\n",
       "      <td>portsweep</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>label</td>\n",
       "      <td>processtable</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>label</td>\n",
       "      <td>ps</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>label</td>\n",
       "      <td>rootkit</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>label</td>\n",
       "      <td>saint</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>label</td>\n",
       "      <td>satan</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>label</td>\n",
       "      <td>sendmail</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>label</td>\n",
       "      <td>smurf</td>\n",
       "      <td>114812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>label</td>\n",
       "      <td>snmpgetattack</td>\n",
       "      <td>5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>label</td>\n",
       "      <td>snmpguess</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>label</td>\n",
       "      <td>sqlattack</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>label</td>\n",
       "      <td>teardrop</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>label</td>\n",
       "      <td>udpstorm.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>label</td>\n",
       "      <td>warezmaster</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>label</td>\n",
       "      <td>worm.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>label</td>\n",
       "      <td>xlock</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>label</td>\n",
       "      <td>xsnoop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>label</td>\n",
       "      <td>xterm.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>217720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"RowId\">RowId</th>\n",
       "      <th title=\"Description\">Description</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "      <th title=\"Numeric Value\">nValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMBEDDINGDIM</td>\n",
       "      <td>Generator Embedding Dimension</td>\n",
       "      <td>128</td>\n",
       "      <td>1.280000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MINIBATCHSIZE</td>\n",
       "      <td>Number of Observations in One Minibatch</td>\n",
       "      <td>500</td>\n",
       "      <td>5.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PACKSIZE</td>\n",
       "      <td>Number of Observations Group Together in Apply...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REGDWEIGHT</td>\n",
       "      <td>Weight for Regularizing the Discriminator</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPTIMIZERAE_BETA1</td>\n",
       "      <td>Exponential Decay Rate for the First Moment Es...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OPTIMIZERAE_BETA2</td>\n",
       "      <td>Exponential Decay Rate for the Second Moment E...</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>9.990000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPTIMIZERAE_LEARNINGRATE</td>\n",
       "      <td>Learning Rate for the Autoencoder's Optimizer</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OPTIMIZERAE_NUMEPOCHS</td>\n",
       "      <td>Number of Epochs for the Autoencoder's Training</td>\n",
       "      <td>300</td>\n",
       "      <td>3.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OPTIMIZERAE_WEIGHTDECAY</td>\n",
       "      <td>Weight Decay for the Autoencoder's Optimizer</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPTIMIZERGAN_BETA1</td>\n",
       "      <td>Exponential Decay Rate for the First Moment Es...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OPTIMIZERGAN_BETA2</td>\n",
       "      <td>Exponential Decay Rate for the Second Moment E...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>9.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OPTIMIZERGAN_LEARNINGRATE</td>\n",
       "      <td>Learning Rate for the GAN Optimizer</td>\n",
       "      <td>2e-05</td>\n",
       "      <td>2.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OPTIMIZERGAN_NUMEPOCHS</td>\n",
       "      <td>Number of Epochs for the GAN Training</td>\n",
       "      <td>300</td>\n",
       "      <td>3.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OPTIMIZERGAN_WEIGHTDECAYD</td>\n",
       "      <td>Weight Decay for the Generator's Optimizer</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OPTIMIZERGAN_WEIGHTDECAYG</td>\n",
       "      <td>Weight Decay for the Discriminator's Optimizer</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SEED</td>\n",
       "      <td>Seed for Random Initialization</td>\n",
       "      <td>12345</td>\n",
       "      <td>1.234500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>USELOGLEVELFREQ</td>\n",
       "      <td>Whether to Use Log Frequency of Categorical Le...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; NObs</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"RowId\">RowId</th>\n",
       "      <th title=\"Description\">Description</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NREAD</td>\n",
       "      <td>Number of Observations Read</td>\n",
       "      <td>217720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NUSED</td>\n",
       "      <td>Number of Observations Used</td>\n",
       "      <td>217720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Label\">Label</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(alphel)</td>\n",
       "      <td>out</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>CASTable('out', caslib='CASUSER(alphel)')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 1.52e+04s</span> &#183; <span class=\"cas-user\">user 2.98e+04s</span> &#183; <span class=\"cas-sys\">sys 1.25e+03s</span> &#183; <span class=\"cas-memory\">mem 30.9MB</span></small></p>"
      ],
      "text/plain": [
       "[IterHistory]\n",
       "\n",
       "      EpochNumber  AutoencoderLoss  GeneratorLoss  DiscriminatorLoss\n",
       " 0              1         0.022121            NaN                NaN\n",
       " 1              2         0.016916            NaN                NaN\n",
       " 2              3         0.012167            NaN                NaN\n",
       " 3              4         0.009169            NaN                NaN\n",
       " 4              5         0.009238            NaN                NaN\n",
       " ..           ...              ...            ...                ...\n",
       " 595          296              NaN       0.310785           0.291099\n",
       " 596          297              NaN       0.358057           0.186845\n",
       " 597          298              NaN       1.095447          -0.122725\n",
       " 598          299              NaN       1.346277           0.262042\n",
       " 599          300              NaN       0.763684           0.598043\n",
       " \n",
       " [600 rows x 4 columns]\n",
       "\n",
       "[LevelFreq]\n",
       "\n",
       "    VarName             Level  Frequency\n",
       " 0        b              icmp     115421\n",
       " 1        b               tcp      83594\n",
       " 2        b               udp      18705\n",
       " 3        d               OTH          2\n",
       " 4        d               REJ      29435\n",
       " 5        d              RSTO        970\n",
       " 6        d              RSTR        601\n",
       " 7        d                S0      12528\n",
       " 8        d                S1         21\n",
       " 9        d                S2         15\n",
       " 10       d                S3        199\n",
       " 11       d                SF     173886\n",
       " 12       d                SH         63\n",
       " 13   label          apache2.        563\n",
       " 14   label              back        763\n",
       " 15   label  buffer_overflow.         16\n",
       " 16   label         ftp_write          2\n",
       " 17   label      guess_passwd       3063\n",
       " 18   label        httptunnel        119\n",
       " 19   label              imap          1\n",
       " 20   label           ipsweep        213\n",
       " 21   label              land          5\n",
       " 22   label        loadmodule          2\n",
       " 23   label          mailbomb       3469\n",
       " 24   label             mscan        755\n",
       " 25   label          multihop         11\n",
       " 26   label             named         13\n",
       " 27   label           neptune      40561\n",
       " 28   label              nmap         63\n",
       " 29   label            normal      42537\n",
       " 30   label              perl          1\n",
       " 31   label               phf          2\n",
       " 32   label               pod         56\n",
       " 33   label         portsweep        248\n",
       " 34   label      processtable        539\n",
       " 35   label                ps         10\n",
       " 36   label           rootkit          9\n",
       " 37   label             saint        508\n",
       " 38   label             satan       1165\n",
       " 39   label          sendmail         10\n",
       " 40   label             smurf     114812\n",
       " 41   label     snmpgetattack       5375\n",
       " 42   label         snmpguess       1676\n",
       " 43   label         sqlattack          2\n",
       " 44   label          teardrop          8\n",
       " 45   label         udpstorm.          1\n",
       " 46   label       warezmaster       1123\n",
       " 47   label             worm.          1\n",
       " 48   label             xlock          8\n",
       " 49   label            xsnoop          2\n",
       " 50   label            xterm.          8\n",
       " 51       t                 0     217720\n",
       "\n",
       "[ModelInfo]\n",
       "\n",
       "                         RowId  \\\n",
       " 0                EMBEDDINGDIM   \n",
       " 1               MINIBATCHSIZE   \n",
       " 2                    PACKSIZE   \n",
       " 3                  REGDWEIGHT   \n",
       " 4           OPTIMIZERAE_BETA1   \n",
       " 5           OPTIMIZERAE_BETA2   \n",
       " 6    OPTIMIZERAE_LEARNINGRATE   \n",
       " 7       OPTIMIZERAE_NUMEPOCHS   \n",
       " 8     OPTIMIZERAE_WEIGHTDECAY   \n",
       " 9          OPTIMIZERGAN_BETA1   \n",
       " 10         OPTIMIZERGAN_BETA2   \n",
       " 11  OPTIMIZERGAN_LEARNINGRATE   \n",
       " 12     OPTIMIZERGAN_NUMEPOCHS   \n",
       " 13  OPTIMIZERGAN_WEIGHTDECAYD   \n",
       " 14  OPTIMIZERGAN_WEIGHTDECAYG   \n",
       " 15                       SEED   \n",
       " 16            USELOGLEVELFREQ   \n",
       " \n",
       "                                           Description     Value        nValue  \n",
       " 0                       Generator Embedding Dimension       128  1.280000e+02  \n",
       " 1             Number of Observations in One Minibatch       500  5.000000e+02  \n",
       " 2   Number of Observations Group Together in Apply...        10  1.000000e+01  \n",
       " 3           Weight for Regularizing the Discriminator        10  1.000000e+01  \n",
       " 4   Exponential Decay Rate for the First Moment Es...  0.900000  9.000000e-01  \n",
       " 5   Exponential Decay Rate for the Second Moment E...  0.999000  9.990000e-01  \n",
       " 6       Learning Rate for the Autoencoder's Optimizer     0.001  1.000000e-03  \n",
       " 7     Number of Epochs for the Autoencoder's Training       300  3.000000e+02  \n",
       " 8        Weight Decay for the Autoencoder's Optimizer     1e-08  1.000000e-08  \n",
       " 9   Exponential Decay Rate for the First Moment Es...  0.500000  5.000000e-01  \n",
       " 10  Exponential Decay Rate for the Second Moment E...  0.900000  9.000000e-01  \n",
       " 11                Learning Rate for the GAN Optimizer     2e-05  2.000000e-05  \n",
       " 12              Number of Epochs for the GAN Training       300  3.000000e+02  \n",
       " 13         Weight Decay for the Generator's Optimizer    0.0001  1.000000e-04  \n",
       " 14     Weight Decay for the Discriminator's Optimizer     1e-06  1.000000e-06  \n",
       " 15                     Seed for Random Initialization     12345  1.234500e+04  \n",
       " 16  Whether to Use Log Frequency of Categorical Le...      True  1.000000e+00  \n",
       "\n",
       "[NObs]\n",
       "\n",
       "    RowId                  Description   Value\n",
       " 0  NREAD  Number of Observations Read  217720\n",
       " 1  NUSED  Number of Observations Used  217720\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib Name Label  Rows  Columns  \\\n",
       " 0  CASUSER(alphel)  out           0       41   \n",
       " \n",
       "                                     casTable  \n",
       " 0  CASTable('out', caslib='CASUSER(alphel)')  \n",
       "\n",
       "+ Elapsed: 1.52e+04s, user: 2.98e+04s, sys: 1.25e+03s, mem: 30.9mb"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = s.tabularGanTrain(\n",
    "table = {\"name\":\"GAN_train\"},\n",
    "    centroidsTable= \"cen\",\n",
    "    gpu = 1,\n",
    "    nominals = [ 'b', 'd', 'label', 't'],\n",
    "    optimizerAe ={\"method\":'ADAM',\"numEpochs\":300},\n",
    "    optimizerGan ={\"method\":'ADAM',\"numEpochs\":300},\n",
    "    seed = 12345,\n",
    "    scoreSeed = 1234,\n",
    "    numSamples =200000,\n",
    "    saveState ={\"name\":\"cpctStore\", \"replace\":True},\n",
    "    casOut = {\"name\":\"out\", \"replace\":True}\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = s.fetch('out', to=400000, maxrows=400000)['Fetch']\n",
    "gloss = results.IterHistory['GeneratorLoss'].dropna().reset_index(drop=True)\n",
    "dloss = results.IterHistory['DiscriminatorLoss'].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses for CPCTGAN on Intrusion data')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(dloss)\n",
    "plt.plot(gloss)\n",
    "plt.legend(['D', 'G'])\n",
    "plt.title('Losses for CPCTGAN on Intrusion data')\n",
    "#plt.savefig('Original-CTGAN-Adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table OUT</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"a\">a</th>\n",
       "      <th title=\"b\">b</th>\n",
       "      <th title=\"d\">d</th>\n",
       "      <th title=\"e\">e</th>\n",
       "      <th title=\"f\">f</th>\n",
       "      <th title=\"g\">g</th>\n",
       "      <th title=\"h\">h</th>\n",
       "      <th title=\"i\">i</th>\n",
       "      <th title=\"j\">j</th>\n",
       "      <th title=\"k\">k</th>\n",
       "      <th title=\"...\">...</th>\n",
       "      <th title=\"ah\">ah</th>\n",
       "      <th title=\"aj\">aj</th>\n",
       "      <th title=\"ak\">ak</th>\n",
       "      <th title=\"al\">al</th>\n",
       "      <th title=\"am\">am</th>\n",
       "      <th title=\"an\">an</th>\n",
       "      <th title=\"ao\">ao</th>\n",
       "      <th title=\"ap\">ap</th>\n",
       "      <th title=\"aq\">aq</th>\n",
       "      <th title=\"label\">label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.156693</td>\n",
       "      <td>tcp</td>\n",
       "      <td>S0</td>\n",
       "      <td>-4.851859e+02</td>\n",
       "      <td>-15.010745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.130608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.180114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.649355</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.544257</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286001</td>\n",
       "      <td>tcp</td>\n",
       "      <td>S3</td>\n",
       "      <td>4.227182e+02</td>\n",
       "      <td>13.350604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>243.688149</td>\n",
       "      <td>0.934954</td>\n",
       "      <td>0.059284</td>\n",
       "      <td>-0.173158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.032855</td>\n",
       "      <td>tcp</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>1.445342e+03</td>\n",
       "      <td>5.609225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>243.416069</td>\n",
       "      <td>0.019138</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>-0.200125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245643</td>\n",
       "      <td>0.396530</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-443.814379</td>\n",
       "      <td>tcp</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>8.779978e+06</td>\n",
       "      <td>4.854925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>253.153482</td>\n",
       "      <td>0.984161</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.088558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.876111</td>\n",
       "      <td>0.332608</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.214487</td>\n",
       "      <td>icmp</td>\n",
       "      <td>OTH</td>\n",
       "      <td>3.006300e+02</td>\n",
       "      <td>12.551514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.706607</td>\n",
       "      <td>0.979959</td>\n",
       "      <td>0.066352</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.896316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>portsweep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.197163</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>6.301154e+02</td>\n",
       "      <td>-1.294215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.019322</td>\n",
       "      <td>0.991101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0.510369</td>\n",
       "      <td>tcp</td>\n",
       "      <td>SF</td>\n",
       "      <td>5.452047e+02</td>\n",
       "      <td>12.290918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.335103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.093439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>852.141679</td>\n",
       "      <td>tcp</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>1.248216e+03</td>\n",
       "      <td>15.574383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>252.447918</td>\n",
       "      <td>0.973758</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.069958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115709</td>\n",
       "      <td>0.022203</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1.280757</td>\n",
       "      <td>tcp</td>\n",
       "      <td>RSTR</td>\n",
       "      <td>1.010230e+03</td>\n",
       "      <td>5.955706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>239.868081</td>\n",
       "      <td>0.921405</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.051952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>0.391364</td>\n",
       "      <td>0.357449</td>\n",
       "      <td>apache2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>-0.019295</td>\n",
       "      <td>tcp</td>\n",
       "      <td>SF</td>\n",
       "      <td>9.461198e+01</td>\n",
       "      <td>5701.860001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.060402</td>\n",
       "      <td>0.988438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298726</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Selected Rows from Table OUT\n",
       "\n",
       "                 a     b     d             e            f    g    h    i    j  \\\n",
       "0        -0.156693   tcp    S0 -4.851859e+02   -15.010745  0.0  0.0  0.0  0.0   \n",
       "1         0.286001   tcp    S3  4.227182e+02    13.350604  0.0  0.0  0.0  0.0   \n",
       "2         2.032855   tcp  RSTR  1.445342e+03     5.609225  0.0  0.0  0.0  0.0   \n",
       "3      -443.814379   tcp  RSTR  8.779978e+06     4.854925  0.0  0.0  0.0  0.0   \n",
       "4         0.214487  icmp   OTH  3.006300e+02    12.551514  0.0  0.0  0.0  0.0   \n",
       "...            ...   ...   ...           ...          ...  ...  ...  ...  ...   \n",
       "199995    0.197163  icmp    SF  6.301154e+02    -1.294215  0.0  0.0  0.0  0.0   \n",
       "199996    0.510369   tcp    SF  5.452047e+02    12.290918  0.0  0.0  0.0  0.0   \n",
       "199997  852.141679   tcp  RSTR  1.248216e+03    15.574383  0.0  0.0  0.0  0.0   \n",
       "199998    1.280757   tcp  RSTR  1.010230e+03     5.955706  0.0  0.0  0.0  0.0   \n",
       "199999   -0.019295   tcp    SF  9.461198e+01  5701.860001  0.0  0.0  0.0  0.0   \n",
       "\n",
       "          k  ...          ah        aj        ak        al        am  \\\n",
       "0       0.0  ...  255.130608  1.000000  0.000000 -0.180114  0.000000   \n",
       "1       0.0  ...  243.688149  0.934954  0.059284 -0.173158  0.000000   \n",
       "2       0.0  ...  243.416069  0.019138  0.061389 -0.200125  0.000000   \n",
       "3       0.0  ...  253.153482  0.984161  0.010000  0.088558  0.000000   \n",
       "4       0.0  ...    4.706607  0.979959  0.066352  0.181421  0.000000   \n",
       "...     ...  ...         ...       ...       ...       ...       ...   \n",
       "199995  0.0  ...  255.019322  0.991101  0.000000  0.866929  0.000000   \n",
       "199996  0.0  ...  254.335103  1.000000  0.015425  0.093439  0.000000   \n",
       "199997  0.0  ...  252.447918  0.973758  0.010000  0.069958  0.000000   \n",
       "199998  0.0  ...  239.868081  0.921405  0.010000 -0.051952  0.000000   \n",
       "199999  0.0  ...   84.060402  0.988438  0.000000  0.298726  0.036728   \n",
       "\n",
       "              an        ao        ap        aq      label  \n",
       "0       0.649355  0.269477  0.318627  0.544257   apache2.  \n",
       "1       0.008637  0.000000  0.421906  0.000000   apache2.  \n",
       "2       0.004958  0.000000  0.245643  0.396530   apache2.  \n",
       "3       0.016318  0.019504  0.876111  0.332608   apache2.  \n",
       "4       0.004483  0.000000  0.896316  0.000000  portsweep  \n",
       "...          ...       ...       ...       ...        ...  \n",
       "199995  0.000000  0.000000  0.000000  0.000000      smurf  \n",
       "199996 -0.001670  0.000000  0.000000  0.000000   apache2.  \n",
       "199997  0.005244  0.000000  0.115709  0.022203   apache2.  \n",
       "199998  0.010734  0.018328  0.391364  0.357449   apache2.  \n",
       "199999  0.000000  0.000000  0.000000  0.000000     normal  \n",
       "\n",
       "[200000 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_icmp</th>\n",
       "      <th>b_tcp</th>\n",
       "      <th>b_udp</th>\n",
       "      <th>d_OTH</th>\n",
       "      <th>d_REJ</th>\n",
       "      <th>d_RSTO</th>\n",
       "      <th>d_RSTR</th>\n",
       "      <th>d_S0</th>\n",
       "      <th>d_S1</th>\n",
       "      <th>d_S2</th>\n",
       "      <th>...</th>\n",
       "      <th>label_snmpgetattack</th>\n",
       "      <th>label_snmpguess</th>\n",
       "      <th>label_sqlattack</th>\n",
       "      <th>label_teardrop</th>\n",
       "      <th>label_udpstorm.</th>\n",
       "      <th>label_warezmaster</th>\n",
       "      <th>label_worm.</th>\n",
       "      <th>label_xlock</th>\n",
       "      <th>label_xsnoop</th>\n",
       "      <th>label_xterm.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b_icmp  b_tcp  b_udp  d_OTH  d_REJ  d_RSTO  d_RSTR  d_S0  d_S1  d_S2  ...  \\\n",
       "0       0      1      0      0      0       0       0     1     0     0  ...   \n",
       "1       0      1      0      0      0       0       0     0     0     0  ...   \n",
       "2       0      1      0      0      0       0       1     0     0     0  ...   \n",
       "3       0      1      0      0      0       0       1     0     0     0  ...   \n",
       "4       1      0      0      1      0       0       0     0     0     0  ...   \n",
       "\n",
       "   label_snmpgetattack  label_snmpguess  label_sqlattack  label_teardrop  \\\n",
       "0                    0                0                0               0   \n",
       "1                    0                0                0               0   \n",
       "2                    0                0                0               0   \n",
       "3                    0                0                0               0   \n",
       "4                    0                0                0               0   \n",
       "\n",
       "   label_udpstorm.  label_warezmaster  label_worm.  label_xlock  label_xsnoop  \\\n",
       "0                0                  0            0            0             0   \n",
       "1                0                  0            0            0             0   \n",
       "2                0                  0            0            0             0   \n",
       "3                0                  0            0            0             0   \n",
       "4                0                  0            0            0             0   \n",
       "\n",
       "   label_xterm.  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using the Ruiwen's Encoder for ML utility and CTGAN transformer for GAN\n",
    "str_cols= [ 'b', 'd', 'label']\n",
    "num_cols = ['a','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','aa','ab','ac','ad','af','ag','ah','aj','ak','al','am','an','ao','ap','aq']\n",
    "dataframe = pd.DataFrame(samples.loc[:,str_cols])\n",
    "\n",
    "one_hot_columns = pd.DataFrame()\n",
    "for col_name, item in dataframe.iteritems():\n",
    "    \n",
    "    #print(col_name)\n",
    "    #print(item)\n",
    "    col = pd.get_dummies(item, prefix=col_name)\n",
    "    one_hot_columns =pd.concat([one_hot_columns,col],axis=1)\n",
    "one_hot_columns.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire data is concat of discrete and contiuous cols\n",
    "fake_all = pd.concat([one_hot_columns,samples.loc[:,num_cols]],axis=1)\n",
    "#fake_all.head()\n",
    "\n",
    "# make sure cols of generated data has the same index sort \n",
    "fake_all = fake_all.reindex(intrusion_data.columns,axis=1, fill_value=0) # fill new cols with 0\n",
    "\n",
    "#fake_all.shape\n",
    "\n",
    "fake_all = fake_all.drop(columns=['label_smurf','label_neptune','label_snmpgetattack','label_mailbomb','label_guess_passwd','label_snmpguess','label_satan','label_warezmaster','label_back','label_mscan','label_apache2.','label_processtable','label_saint','label_portsweep','label_ipsweep','label_httptunnel','label_pod','label_nmap','label_buffer_overflow.','label_multihop','label_sendmail','label_named','label_ps','label_rootkit','label_xterm.','label_teardrop','label_land','label_xlock','label_xsnoop','label_ftp_write','label_phf','label_udpstorm.','label_perl','label_sqlattack','label_worm.','label_loadmodule','label_imap'])\n",
    "fake_X = fake_all.rename(columns={'label_normal':'label'})\n",
    "\n",
    "fake_X, fake_y = fake_X.drop(columns=[\"label\"]),fake_X.loc[:,\"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the GAN generated train data:  (200000, 52)\n",
      "shape of the GAN generated labels:  (200000,)\n",
      "shape of the original test data:  (93309, 52)\n",
      "number of events in the fake data:  8716\n"
     ]
    }
   ],
   "source": [
    "# check the training data shape to agree with the original data (# of features/cols)\n",
    "print('shape of the GAN generated train data: ',fake_X.shape)\n",
    "print('shape of the GAN generated labels: ',fake_y.shape)\n",
    "print('shape of the original test data: ',orig_X_test.shape)\n",
    "print('number of events in the fake data: ', sum(fake_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML scores for the GAN generated data:\n",
      "Decision Tree Acc:  0.9401558263404387 f-1:  0.8511250933134263 AUC: 0.977656354439695\n",
      "Linear SVM Acc:  0.19465432059072543 f-1:  0.32585136541428933 AUC: 0.9597929477223864\n",
      "Random Forest Acc:  0.9553633625909612 f-1:  0.8921403599637447 AUC: 0.9914918788587084\n",
      "Logistic Regression Acc:  0.8635608569377016 f-1:  0.47215887889215963 AUC: 0.9689794881748477\n",
      "MLP Acc:  0.8912109228477424 f-1:  0.6239674013706242 AUC: 0.9702205035031641\n"
     ]
    }
   ],
   "source": [
    "# train a classifier on the CPCTGAN generated data\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=5,random_state=0),\n",
    "    SVC(kernel = 'linear', max_iter=1000, C=0.025, random_state=0, probability=True),\n",
    "    RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    LogisticRegression(max_iter=1000, random_state=0),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=0)]\n",
    "\n",
    "print('ML scores for the GAN generated data:')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(fake_X, fake_y)\n",
    "    score = clf.score(orig_X_test, orig_y_test)\n",
    "    y_pred = clf.predict(orig_X_test)\n",
    "    Acc = accuracy_score(orig_y_test, y_pred)\n",
    "    fscore = f1_score(orig_y_test, y_pred, average='binary')\n",
    "    AUC = roc_auc_score(orig_y_test, clf.predict_proba(orig_X_test)[:, 1])\n",
    "    print(name,'Acc: ', Acc, 'f-1: ', fscore, 'AUC:', AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    155168\n",
       "1     44832\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75131\n",
       "1    18178\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CTGAN on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctgan import CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215174</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214746</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>SF</td>\n",
       "      <td>267</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151318</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278297</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261219</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192476</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17730</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28030</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277869</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249342</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>SF</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smurf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217720 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration protocol_type flag  src_bytes  dst_bytes  land  \\\n",
       "215174         0          icmp   SF       1032          0     0   \n",
       "214746         0           tcp   SF        267        390     0   \n",
       "151318         0           udp   SF          1          0     0   \n",
       "278297         0          icmp   SF        520          0     0   \n",
       "261219         0          icmp   SF        520          0     0   \n",
       "...          ...           ...  ...        ...        ...   ...   \n",
       "192476         0          icmp   SF       1032          0     0   \n",
       "17730          0          icmp   SF       1032          0     0   \n",
       "28030          0          icmp   SF       1032          0     0   \n",
       "277869         0          icmp   SF        520          0     0   \n",
       "249342         0          icmp   SF        520          0     0   \n",
       "\n",
       "        wrong_fragment  urgent  hot  num_failed_logins  ...  \\\n",
       "215174               0       0    0                  0  ...   \n",
       "214746               0       0    0                  0  ...   \n",
       "151318               0       0    0                  0  ...   \n",
       "278297               0       0    0                  0  ...   \n",
       "261219               0       0    0                  0  ...   \n",
       "...                ...     ...  ...                ...  ...   \n",
       "192476               0       0    0                  0  ...   \n",
       "17730                0       0    0                  0  ...   \n",
       "28030                0       0    0                  0  ...   \n",
       "277869               0       0    0                  0  ...   \n",
       "249342               0       0    0                  0  ...   \n",
       "\n",
       "        dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "215174                 187                    0.73                    0.01   \n",
       "214746                 160                    1.00                    0.00   \n",
       "151318                   1                    0.00                    0.74   \n",
       "278297                 255                    1.00                    0.00   \n",
       "261219                 255                    1.00                    0.00   \n",
       "...                    ...                     ...                     ...   \n",
       "192476                 255                    1.00                    0.00   \n",
       "17730                  255                    1.00                    0.00   \n",
       "28030                  255                    1.00                    0.00   \n",
       "277869                 255                    1.00                    0.00   \n",
       "249342                 255                    1.00                    0.00   \n",
       "\n",
       "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "215174                         0.73                         0.00   \n",
       "214746                         0.03                         0.02   \n",
       "151318                         1.00                         0.00   \n",
       "278297                         1.00                         0.00   \n",
       "261219                         1.00                         0.00   \n",
       "...                             ...                          ...   \n",
       "192476                         1.00                         0.00   \n",
       "17730                          1.00                         0.00   \n",
       "28030                          1.00                         0.00   \n",
       "277869                         1.00                         0.00   \n",
       "249342                         1.00                         0.00   \n",
       "\n",
       "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "215174                   0.0                       0.0                   0.0   \n",
       "214746                   0.0                       0.0                   0.0   \n",
       "151318                   0.0                       0.0                   0.0   \n",
       "278297                   0.0                       0.0                   0.0   \n",
       "261219                   0.0                       0.0                   0.0   \n",
       "...                      ...                       ...                   ...   \n",
       "192476                   0.0                       0.0                   0.0   \n",
       "17730                    0.0                       0.0                   0.0   \n",
       "28030                    0.0                       0.0                   0.0   \n",
       "277869                   0.0                       0.0                   0.0   \n",
       "249342                   0.0                       0.0                   0.0   \n",
       "\n",
       "        dst_host_srv_rerror_rate   label  \n",
       "215174                       0.0   smurf  \n",
       "214746                       0.0  normal  \n",
       "151318                       0.0   satan  \n",
       "278297                       0.0   smurf  \n",
       "261219                       0.0   smurf  \n",
       "...                          ...     ...  \n",
       "192476                       0.0   smurf  \n",
       "17730                        0.0   smurf  \n",
       "28030                        0.0   smurf  \n",
       "277869                       0.0   smurf  \n",
       "249342                       0.0   smurf  \n",
       "\n",
       "[217720 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAN_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duration,protocol_type,flag,land,wrong_fragment,urgent,hot,num_failed_logins,logged_in,num_compromised,root_shell,su_attempted,num_root,num_file_creations,num_shells,num_access_files,num_outbound_cmds,is_host_login,is_guest_login,serror_rate,srv_serror_rate,rerror_rate,srv_rerror_rate,label'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G: -2.3438,Loss D: -0.1776\n",
      "Epoch 2, Loss G: -2.2153,Loss D: -0.6098\n"
     ]
    }
   ],
   "source": [
    "# train CTGAN and generate fake data\n",
    "# from synthesizer import CTGANSynthesizer\n",
    "ctgan = CTGANSynthesizer(verbose=True)\n",
    "ctgan.fit(GAN_train, discrete, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ctgan.sample(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type_icmp</th>\n",
       "      <th>protocol_type_tcp</th>\n",
       "      <th>protocol_type_udp</th>\n",
       "      <th>flag_OTH</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>...</th>\n",
       "      <th>label_snmpgetattack</th>\n",
       "      <th>label_snmpguess</th>\n",
       "      <th>label_sqlattack</th>\n",
       "      <th>label_teardrop</th>\n",
       "      <th>label_udpstorm.</th>\n",
       "      <th>label_warezmaster</th>\n",
       "      <th>label_worm.</th>\n",
       "      <th>label_xlock</th>\n",
       "      <th>label_xsnoop</th>\n",
       "      <th>label_xterm.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   protocol_type_icmp  protocol_type_tcp  protocol_type_udp  flag_OTH  \\\n",
       "0                   0                  0                  1         0   \n",
       "1                   0                  1                  0         1   \n",
       "2                   0                  1                  0         0   \n",
       "3                   1                  0                  0         0   \n",
       "4                   1                  0                  0         0   \n",
       "\n",
       "   flag_REJ  flag_RSTO  flag_RSTR  flag_S0  flag_S1  flag_S2  ...  \\\n",
       "0         0          0          0        0        0        0  ...   \n",
       "1         0          0          0        0        0        0  ...   \n",
       "2         1          0          0        0        0        0  ...   \n",
       "3         0          0          0        0        0        0  ...   \n",
       "4         0          0          0        0        0        0  ...   \n",
       "\n",
       "   label_snmpgetattack  label_snmpguess  label_sqlattack  label_teardrop  \\\n",
       "0                    0                1                0               0   \n",
       "1                    0                0                0               0   \n",
       "2                    0                0                0               0   \n",
       "3                    0                0                0               0   \n",
       "4                    0                0                0               0   \n",
       "\n",
       "   label_udpstorm.  label_warezmaster  label_worm.  label_xlock  label_xsnoop  \\\n",
       "0                0                  0            0            0             0   \n",
       "1                0                  0            0            0             0   \n",
       "2                0                  0            0            0             0   \n",
       "3                0                  0            0            0             0   \n",
       "4                0                  0            0            0             0   \n",
       "\n",
       "   label_xterm.  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using the Ruiwen's Encoder for ML utility and CTGAN transformer for GAN\n",
    "str_cols= [ 'protocol_type', 'flag', 'label']\n",
    "num_cols = ['duration','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate']\n",
    "dataframe = pd.DataFrame(samples.loc[:,str_cols])\n",
    "\n",
    "one_hot_columns = pd.DataFrame()\n",
    "for col_name, item in dataframe.iteritems():\n",
    "    \n",
    "    #print(col_name)\n",
    "    #print(item)\n",
    "    col = pd.get_dummies(item, prefix=col_name)\n",
    "    one_hot_columns =pd.concat([one_hot_columns,col],axis=1)\n",
    "one_hot_columns.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire data is concat of discrete and contiuous cols\n",
    "fake_all = pd.concat([one_hot_columns,samples.loc[:,num_cols]],axis=1)\n",
    "#fake_all.head()\n",
    "\n",
    "# make sure cols of generated data has the same index sort \n",
    "fake_all = fake_all.reindex(intrusion_data.columns,axis=1, fill_value=0) # fill new cols with 0\n",
    "\n",
    "#fake_all.shape\n",
    "\n",
    "fake_all = fake_all.drop(columns=['label_smurf','label_neptune','label_snmpgetattack','label_mailbomb','label_guess_passwd','label_snmpguess','label_satan','label_warezmaster','label_back','label_mscan','label_apache2.','label_processtable','label_saint','label_portsweep','label_ipsweep','label_httptunnel','label_pod','label_nmap','label_buffer_overflow.','label_multihop','label_sendmail','label_named','label_ps','label_rootkit','label_xterm.','label_teardrop','label_land','label_xlock','label_xsnoop','label_ftp_write','label_phf','label_udpstorm.','label_perl','label_sqlattack','label_worm.','label_loadmodule','label_imap'])\n",
    "fake_X = fake_all.rename(columns={'label_normal':'label'})\n",
    "\n",
    "fake_X, fake_y = fake_X.drop(columns=[\"label\"]),fake_X.loc[:,\"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the GAN generated train data:  (200000, 52)\n",
      "shape of the GAN generated labels:  (200000,)\n",
      "shape of the original test data:  (93309, 52)\n",
      "number of events in the fake data:  57884\n"
     ]
    }
   ],
   "source": [
    "# check the training data shape to agree with the original data (# of features/cols)\n",
    "print('shape of the GAN generated train data: ',fake_X.shape)\n",
    "print('shape of the GAN generated labels: ',fake_y.shape)\n",
    "print('shape of the original test data: ',orig_X_test.shape)\n",
    "print('number of events in the fake data: ', sum(fake_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML scores for the GAN generated data:\n",
      "Decision Tree Acc:  0.9432101940863153 f-1:  0.8406459567557814 AUC: 0.9879786724638909\n",
      "Linear SVM Acc:  0.8156447931067743 f-1:  0.10294117647058823 AUC: 0.961971616367371\n",
      "Random Forest Acc:  0.9440568433913127 f-1:  0.8633078453964597 AUC: 0.9897834432614219\n",
      "Logistic Regression Acc:  0.9254412757611806 f-1:  0.7906220844493935 AUC: 0.9695149961406978\n",
      "MLP Acc:  0.9323109239194505 f-1:  0.8334300332296006 AUC: 0.9759709899981952\n"
     ]
    }
   ],
   "source": [
    "# train a classifier on the CPCTGAN generated data\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=5,random_state=0),\n",
    "    SVC(kernel = 'linear', max_iter=1000, C=0.025, random_state=0, probability=True),\n",
    "    RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    LogisticRegression(max_iter=1000, random_state=0),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=0)]\n",
    "\n",
    "print('ML scores for the GAN generated data:')\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(fake_X, fake_y)\n",
    "    score = clf.score(orig_X_test, orig_y_test)\n",
    "    y_pred = clf.predict(orig_X_test)\n",
    "    Acc = accuracy_score(orig_y_test, y_pred)\n",
    "    fscore = f1_score(orig_y_test, y_pred, average='binary')\n",
    "    AUC = roc_auc_score(orig_y_test, clf.predict_proba(orig_X_test)[:, 1])\n",
    "    print(name,'Acc: ', Acc, 'f-1: ', fscore, 'AUC:', AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
